import os
import tempfile
import whisper
import gradio as gr
import soundfile as sf
from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer
from TTS.api import TTS

# ---------------------------
# æ”¯æŒè¯­è¨€æ˜ å°„ï¼ˆå·²å»é™¤è¥¿ç­ç‰™è¯­ï¼‰
# ---------------------------
TGT_LANG_MAP = {
    "è‹±è¯­ï¼ˆenï¼‰": "en",
    "æ³•è¯­ï¼ˆfrï¼‰": "fr",
    "å¾·è¯­ï¼ˆdeï¼‰": "de",
}

TTS_MODELS = {
    "en": "tts_models/en/ljspeech/tacotron2-DDC",
    "fr": "tts_models/fr/css10/vits",
    "de": "tts_models/de/thorsten/tacotron2-DCA",
}

# ---------------------------
# åŠ è½½ Whisper ASR æ¨¡å‹
# ---------------------------
print("Loading Whisper ASR...")
asr_model = whisper.load_model("tiny")

# ---------------------------
# åŠ è½½ M2M100 ç¿»è¯‘æ¨¡å‹
# ---------------------------
print("Loading M2M100 translation model...")
MT_MODEL_NAME = "facebook/m2m100_418M"
tokenizer = M2M100Tokenizer.from_pretrained(MT_MODEL_NAME)
mt_model = M2M100ForConditionalGeneration.from_pretrained(MT_MODEL_NAME)

# ---------------------------
# ç¿»è¯‘ä¸»å‡½æ•°ï¼ˆæ”¯æŒå¤šè¯­è¨€ï¼‰
# ---------------------------
def translate_audio(audio, lang_display):
    tgt_lang = TGT_LANG_MAP[lang_display]

    # ä¿å­˜ä¸Šä¼ çš„éŸ³é¢‘
    if isinstance(audio, tuple):
        sr, data = audio
        tmp = tempfile.NamedTemporaryFile(suffix=".wav", delete=False)
        sf.write(tmp.name, data, sr)
        wav_path = tmp.name
    else:
        wav_path = audio

    # ASRï¼šä¸­æ–‡è¯†åˆ«
    res = asr_model.transcribe(wav_path, language="zh")
    zh = res["text"].strip()

    # MTï¼šä¸­æ–‡ â†’ ç›®æ ‡è¯­è¨€
    tokenizer.src_lang = "zh"
    inputs = tokenizer(zh, return_tensors="pt")
    gen = mt_model.generate(
        **inputs,
        forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang]
    )
    translated = tokenizer.decode(gen[0], skip_special_tokens=True)

    # TTSï¼šç›®æ ‡è¯­è¨€è¯­éŸ³åˆæˆ
    tts_model = TTS(model_name=TTS_MODELS[tgt_lang], progress_bar=False, gpu=False)
    out_wav = tempfile.NamedTemporaryFile(suffix=".wav", delete=False).name
    tts_model.tts_to_file(text=translated, file_path=out_wav)

    return zh, translated, out_wav

# ---------------------------
# Gradio ç½‘é¡µç•Œé¢
# ---------------------------
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ™ï¸ ä¸­æ–‡è¯­éŸ³ â†’ å¤šè¯­è¨€è¯­éŸ³ç¿»è¯‘æ¼”ç¤º")

    with gr.Row():
        audio_in = gr.Audio(sources=["upload"], type="filepath", label="ä¸Šä¼ ä¸­æ–‡è¯­éŸ³ (WAV)")
        lang_dropdown = gr.Dropdown(label="é€‰æ‹©è¾“å‡ºè¯­è¨€", choices=list(TGT_LANG_MAP.keys()), value="è‹±è¯­ï¼ˆenï¼‰")

    with gr.Row():
        txt_zh = gr.Textbox(label="ASR è¾“å‡ºï¼ˆä¸­æ–‡ï¼‰")
        txt_mt = gr.Textbox(label="MT ç¿»è¯‘è¾“å‡º")
        audio_out = gr.Audio(label="TTS åˆæˆè¯­éŸ³")

    btn = gr.Button("ç¿»è¯‘å¹¶åˆæˆ")
    btn.click(fn=translate_audio, inputs=[audio_in, lang_dropdown], outputs=[txt_zh, txt_mt, audio_out])

if __name__ == "__main__":
    demo.launch(share=True)
